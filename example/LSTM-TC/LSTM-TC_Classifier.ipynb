{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f797971",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  torch tqdm tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a713ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T06:56:36.015748Z",
     "start_time": "2022-03-21T06:56:35.985751Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec7ae37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T06:56:39.624167Z",
     "start_time": "2022-03-21T06:56:39.609167Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'e:\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d422e901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:01:28.543319Z",
     "start_time": "2022-03-21T06:56:39.992064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185472it [04:48, 642.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set = []\n",
    "with open(os.path.join(data_path, 'train_set_full.jl'), 'r') as f:\n",
    "    for l in tqdm(f):\n",
    "        d = json.loads(l)\n",
    "        train_set.append((d[0][1:], d[1][1:], d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4508467b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:26.970500Z",
     "start_time": "2022-03-21T07:01:28.548320Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_set = []\n",
    "with open(os.path.join(data_path, 'dev_set_full.jl'), 'r') as f:\n",
    "#     for i in range(5000):\n",
    "    for l in f:\n",
    "#         l = f.readline()\n",
    "        d = json.loads(l)\n",
    "        dev_set.append((d[0][1:], d[1][1:], d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1104f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:47.964034Z",
     "start_time": "2022-03-21T07:03:34.555821Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import sklearn.metrics\n",
    "device = torch.device('cpu') # torch.device('cuda') \n",
    "max_len1 = 30\n",
    "max_len2 = 10\n",
    "batch_size = 512\n",
    "data_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9559b308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:47.979035Z",
     "start_time": "2022-03-21T07:03:47.968036Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        s1 = example[0]\n",
    "        s2 = example[1]\n",
    "        label = example[2]\n",
    "        l1 = len(s1)\n",
    "        l2 = len(s2)\n",
    "        if l1 < max_len1:\n",
    "            s1 += [[0] * 78 for _ in range(max_len1 - l1)]\n",
    "        if l2 < max_len2:\n",
    "            s2 += [[0] * 78 for _ in range(max_len2 - l2)]\n",
    "        return s1, l1, s2, l2, label, index\n",
    "\n",
    "def the_collate_fn(batch):\n",
    "    #print(batch)\n",
    "    s1 = [b[0] for b in batch]\n",
    "    s2 = [b[2] for b in batch]\n",
    "    l1 = [b[1] for b in batch]\n",
    "    l2 = [b[3] for b in batch]\n",
    "    label = torch.Tensor([b[4] for b in batch])\n",
    "    indexs = [b[5] for b in batch]\n",
    "#     print(type(s1), len(s1))\n",
    "#     for p in s1:\n",
    "#         print(type(p), len(p))\n",
    "    s1 = torch.FloatTensor(s1)\n",
    "    s2 = torch.FloatTensor(s2)\n",
    "    return s1, l1,s2, l2, label, indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb7a12a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:47.995034Z",
     "start_time": "2022-03-21T07:03:47.981035Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataSet(train_set)\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers=data_workers,\n",
    "    collate_fn=the_collate_fn,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "dev_dataset = MyDataSet(dev_set)\n",
    "dev_data_loader = torch.utils.data.DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers=data_workers,\n",
    "    collate_fn=the_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6192e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:48.010035Z",
     "start_time": "2022-03-21T07:03:47.997034Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoubleLSTMClassify(nn.Module):\n",
    "    def __init__(self, embedding_dim=78, hidden_dim=256):\n",
    "        super(DoubleLSTMClassify, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "#         self.embedding = nn.Embedding(word_size, embedding_dim)\n",
    "#         self.embedding.from_pretrained(torch.FloatTensor(vec))\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.cls = nn.Linear(hidden_dim*2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, s1, length1, s2, length2, label=None):\n",
    "        batch_size = s1.shape[0]\n",
    "#         b1 = self.embedding(s1)\n",
    "#         b2 = self.embedding(s2)\n",
    "        l1 = self.lstm1(s1)[0]\n",
    "        l2 = self.lstm2(s2)[0]\n",
    "        x = torch.zeros(batch_size, self.hidden_dim*2).to(device)\n",
    "        for b in range(batch_size):\n",
    "            x[b][:self.hidden_dim] = l1[b][length1[b]-1]\n",
    "            x[b][self.hidden_dim:] = l2[b][length2[b]-1]\n",
    "        r = self.cls(x)\n",
    "        r = self.sigmoid(r)\n",
    "        if label != None:\n",
    "            criterion = nn.BCELoss()\n",
    "            return criterion(r.squeeze(1), label)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aee8f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:48.025039Z",
     "start_time": "2022-03-21T07:03:48.011035Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalx(pred, truth, th):\n",
    "    predx = []\n",
    "    for x in pred:\n",
    "        if x > th:\n",
    "            predx.append(1)\n",
    "        else:\n",
    "            predx.append(0)\n",
    "    prec,rec,f1,num = precision_recall_fscore_support(truth,predx, average=\"binary\")\n",
    "    accuracy = sklearn.metrics.accuracy_score(truth, predx)\n",
    "    return prec, rec, f1, accuracy\n",
    "\n",
    "\n",
    "def eval(th=0.5):\n",
    "    predv = []\n",
    "    truth =[]\n",
    "    for batch in tqdm(dev_data_loader):\n",
    "        with torch.no_grad():\n",
    "    #         model.test()\n",
    "            s1, l1, s2, l2, label, index = batch\n",
    "            s1 = s1.to(device)\n",
    "            s2 = s2.to(device)\n",
    "            label = label.to(device)\n",
    "            r = model(s1, l1, s2, l2)\n",
    "            truth += label\n",
    "#             pred += predx\n",
    "            predv += r\n",
    "    for i in range(len(truth)):\n",
    "        truth[i] = int(truth[i].cpu().item())\n",
    "    if th is not None:\n",
    "        maxp, maxr,maxf1, maxa = evalx(predv, truth, th)\n",
    "        maxth = th\n",
    "    else:\n",
    "        maxf1 = 0\n",
    "        maxp, maxr, maxa, maxth = 0,0,0,0\n",
    "        for t in tqdm(predv + [max(predv)+1]):\n",
    "            prec, rec, f1, accuracy = evalx(predv, truth, t)\n",
    "            if f1 > maxf1:\n",
    "                print(prec, rec, f1, accuracy)\n",
    "                maxp, maxr,maxf1, maxa, maxth = prec, rec, f1, accuracy, t\n",
    "#     prec,rec,f1,num = precision_recall_fscore_support(truth,pred, average=\"binary\")\n",
    "#     accuracy = sklearn.metrics.accuracy_score(truth, pred)\n",
    "#     print(len(truth), sum(pred), sum(truth))\n",
    "#     print('p=%.4f\\tr=%.4f\\tf1=%.4f\\ta=%.4f' % (prec,rec,f1, accuracy))\n",
    "    return maxp, maxr, maxf1, maxth, predv, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6718116f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:48.057038Z",
     "start_time": "2022-03-21T07:03:48.027038Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DoubleLSTMClassify(78)\n",
    "model.to(device)\n",
    "learning_rate = 0.2#0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,  milestones = [20, 40, 50,60, 70, 80, 90], gamma = 0.5, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a4646d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:48.073037Z",
     "start_time": "2022-03-21T07:03:48.059035Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_res(pred, trut):\n",
    "    predv = [x.cpu().item() for x in pred]\n",
    "    trutv = trut\n",
    "    if True:\n",
    "        pos_l = []\n",
    "        neg_l = []\n",
    "        for i in range(len(trutv)):\n",
    "            if trutv[i] == 1:\n",
    "                pos_l.append(predv[i])\n",
    "            else:\n",
    "                neg_l.append(predv[i])\n",
    "        pos_l.sort()\n",
    "        neg_l.sort()\n",
    "        tar = list(set(predv))\n",
    "        tar.sort()\n",
    "        tar = [0] + tar + [tar[-1] + 1]\n",
    "        i, j = 0, 0\n",
    "        rl = []\n",
    "        \n",
    "        for x in tar:\n",
    "            while  i < len(pos_l) and pos_l[i] < x:\n",
    "                i += 1\n",
    "            while j < len(neg_l) and neg_l[j] < x:\n",
    "                j += 1\n",
    "            tp = len(pos_l) - i\n",
    "            fp = len(neg_l) - j\n",
    "            tn = j\n",
    "            fn = i\n",
    "            precision = 0 if (tp+fp) == 0 else tp / (tp+fp)\n",
    "            recall = 0 if (tp + fn) == 0 else tp / (tp + fn)\n",
    "            f1 = 0 if (precision+recall) == 0 else  2*(precision*recall) / (precision+recall)\n",
    "            rl.append([precision, recall, f1])\n",
    "        rl.sort(key = lambda x: (-x[2], -x[0], -x[1]))\n",
    "        r1 = rl[::]\n",
    "        rl.sort(key = lambda x: (-x[0], -x[1], -x[2]))\n",
    "        r2 = rl[::]\n",
    "        return r1, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1590b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:48.134039Z",
     "start_time": "2022-03-21T07:03:48.075037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file full_train-1 already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir full_train-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4c23bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T07:03:55.410943Z",
     "start_time": "2022-03-21T07:03:55.398937Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "bf15 = 0\n",
    "bf1a = 0\n",
    "import time\n",
    "def log(x):\n",
    "    with open('full-1.log', 'a') as f:\n",
    "        f.write(str(time.time()) + '\\n')\n",
    "        f.write(x + '\\n')\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fea74a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-21T07:04:17.691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/363 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "loss_sum = 0\n",
    "for batch in tqdm(train_data_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad61884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfb77d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-21T05:03:43.176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/363 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "bf15 = 0\n",
    "bf1a = 0\n",
    "import time\n",
    "def log(x):\n",
    "    with open('full-1.log', 'a') as f:\n",
    "        f.write(str(time.time()) + '\\n')\n",
    "        f.write(x + '\\n')\n",
    "    print(x)\n",
    "# result_list = []\n",
    "for b in range(40):\n",
    "    print('epoch', b)\n",
    "    i = 0\n",
    "    loss_sum = 0\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        i += 1\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        s1, l1, s2, l2, label, index = batch\n",
    "        s1 = s1.to(device)\n",
    "        s2 = s2.to(device)\n",
    "        label = label.to(device)\n",
    "        loss = model(s1, l1,s2, l2, label)\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "    xresult = eval()\n",
    "    r1, r2 = get_res(*xresult[4:])\n",
    "    save_flag = False\n",
    "    if xresult[2] > bf15:\n",
    "        bf15 = xresult[2]\n",
    "        save_flag = True\n",
    "    elif r1[0][2] > bf1a:\n",
    "        bf1a = r1[0][2]\n",
    "        save_flag = True\n",
    "    if save_flag:\n",
    "        torch.save(model, 'full_train-1/model_20201223_%.2f_%.2f_epoch_%d_layer_3.pkl' % (xresult[2], r1[0][2], b))\n",
    "    log(str(('train loss', loss_sum / i, xresult[:4], bf15, bf1a)))\n",
    "    loss_list.append(loss_sum / i)\n",
    "#     result_list.append(xresult)\n",
    "    print()\n",
    "#     eval(0.0006)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
